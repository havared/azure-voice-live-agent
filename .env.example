# =============================================================================
# Azure Voice Live Configuration
# =============================================================================

# Your Azure AI Foundry endpoint (WebSocket URL from Azure portal)
AZURE_OPENAI_ENDPOINT=wss://<your-resource-name>.services.ai.azure.com

# API key (Keys & Endpoint section in portal — use KEY1 or KEY2)
AZURE_OPENAI_KEY=<your-api-key>

# Model name for the realtime model (passed as ?model= query parameter)
AZURE_MODEL=gpt-realtime

# API version
AZURE_API_VERSION=2025-10-01

# =============================================================================
# Voice Configuration (Azure TTS)
# =============================================================================

# Azure TTS voice name (see https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts)
# HD voices: en-US-Ava:DragonHDLatestNeural, en-US-Andrew:DragonHDLatestNeural, etc.
VOICE_NAME=en-US-AvaNeural

# Temperature for HD voices (higher = more expressive). Ignored for non-HD voices.
VOICE_TEMPERATURE=0.8

# =============================================================================
# Azure Semantic VAD Configuration
# =============================================================================

# Confidence threshold for speech detection (0.0–1.0)
VAD_THRESHOLD=0.3

# Audio to include before speech detection signal (ms)
VAD_PREFIX_PADDING_MS=200

# Silence duration to detect end of speech (ms)
VAD_SILENCE_DURATION_MS=200

# Remove filler words (umm, uh, etc.) to reduce false barge-in
REMOVE_FILLER_WORDS=false

# =============================================================================
# End-of-Utterance Detection
# Only supported with cascaded (non-realtime) models like gpt-4o.
# Not supported with gpt-realtime, gpt-4o-mini-realtime, phi4-mm-realtime.
# =============================================================================

# Set to true when using a cascaded model
EOU_ENABLED=false

# Threshold level: low, default, medium, high
EOU_THRESHOLD_LEVEL=default

# Max time (ms) to wait for more user speech before ending turn
EOU_TIMEOUT_MS=1000

# =============================================================================
# Input Audio Transcription
# Transcribes user speech so it appears in the browser conversation log.
# Supported models: whisper-1, gpt-4o-transcribe, gpt-4o-mini-transcribe, azure-speech
# =============================================================================

INPUT_AUDIO_TRANSCRIPTION_MODEL=azure-speech

# Language code in BCP-47 (e.g., "en-US") or ISO-639-1 (e.g., "en")
INPUT_AUDIO_TRANSCRIPTION_LANGUAGE=en

# =============================================================================
# Agent Instructions
# =============================================================================

# Path to the markdown file containing agent system instructions
AGENT_INSTRUCTIONS_FILE=agent_instructions.md

# =============================================================================
# Application Settings
# =============================================================================

APP_HOST=0.0.0.0
APP_PORT=8000
LOG_LEVEL=INFO

# If true, the agent speaks first with a greeting when session starts
ENABLE_PROACTIVE_GREETING=true

# Password for the admin login page
ADMIN_PASSWORD=admin
